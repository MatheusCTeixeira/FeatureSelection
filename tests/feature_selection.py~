import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
import numpy as np
import pandas as pd
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from scipy import interp
from sklearn.metrics import roc_auc_score
from numpy.random import Generator, PCG64
import argparse

seed = 100

def load(filename):
    f = open(filename, "rt", encoding="utf-8")
    df = pd.read_csv(f)
    return df

class Fitness:
    def __init__(self, classifier, X, y, prop_train, random_state):
        self._classifier = OneVsRestClassifier(classifier)
        self._X = X
        self._y = label_binarize(y, classes=["bot", "human", "news"])
        self._n_classes = self._y.shape[1]
        self._prop_train = prop_train
        self._random_state = random_state
        self._cache = dict()

    def __call__(self, population):
        n_individuals = population.shape[0]
        pop_fitness = np.zeros(n_individuals)

        for i in range(n_individuals):
            pop_fitness[i] = self._calc(population[i])

        return pop_fitness
        
    def _calc(self, individual):
        ind_str = "".join(map(str, individual))
        if ind_str in self._cache: return self._cache[ind_str]
        # select a subset of columns.
        X, y = self._select_columns(self._X, individual), self._y

        # Split dataset in train/test
        X_train, X_test, y_train, y_test = \
            train_test_split(X, y, test_size=self._prop_train,
                             random_state=self._random_state)

        # Predict the test set
        y_score = self._classifier.fit(X_train, y_train).predict_proba(X_test)
        fpr, tpr, roc_auc = dict(), dict(), dict()

        for i in range(self._n_classes):
            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])

        # fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
        # roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(self._n_classes)]))
        mean_tpr = np.zeros_like(all_fpr)

        for i in range(self._n_classes):
            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])

        mean_tpr /= self._n_classes
        fpr["macro"] = all_fpr
        tpr["macro"] = mean_tpr
        roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

        self._cache[ind_str] = roc_auc["macro"]
        return roc_auc["macro"]

    def _select_columns(self, X, individual):
        # Select columns where X == 1.
        index = individual == 1
        return X.iloc[:, index]


class FS:
    def __init__(self,
                 classifier,
                 X,
                 y,
                 pop_sz,
                 crossover_prob,
                 mut_prob,
                 k,
                 prop_train,
                 random_state):

        self._classifier = classifier
        self._X = X        
        self._y = y
        self._crossover_prob = crossover_prob
        self._mut_prob = mut_prob
        self._k = k
        self._prop_train = prop_train
        self._random_state = random_state

        self._pop_sz = (pop_sz, X.shape[1])
        self._fitness = Fitness(classifier, X, y, prop_train, random_state)
        self._rd = Generator(PCG64(random_state))

        
    def generate_initial_population(self):
        self._pop = self._rd.integers(0, 1, self._pop_sz, endpoint=True)
        self._eval_fitness()

        
    def next_generation(self):
        new_gen = np.zeros(self._pop.shape, dtype=np.int)
        n_ind, ind_sz = self._pop_sz

        for i in range(0, n_ind, 2):
            p1, p2 = self.crossover()
            new_gen[i], new_gen[i+1] = p1, p2

        if n_ind % 2:
            new_gen[-1] = self.crossover()[0]

        for i in range(n_ind):
            self.mutation(new_gen[i])

        self._pop = np.vstack((self._pop, new_gen))
        self._eval_fitness()
        self._pop = self._pop[:n_ind, :]
        print(np.max(self._pop_fitness))
            
        
    def crossover(self):
        i1, i2 = self._selection(), self._selection()
        split_point = self._rd.integers(0, self._pop_sz[1])
        temp = self._pop[i1,:]
        p1, p2 = self._pop[i1,:], self._pop[i2,:]
        p1[split_point:] = p2[split_point:]
        p2[:split_point] = temp[:split_point]
        return p1, p2

    
    def mutation(self, p1):
        for i in range(self._pop_sz[1]):
            if self._rd.random() > self._mut_prob:
                p1[i] = (p1[i] + 1) % 2

        return p1

    
    def _eval_fitness(self):
        pop_fitness = self._fitness(self._pop)
        sorted_fitness = np.argsort(-pop_fitness)

        self._pop = self._pop[sorted_fitness, :]
        self._pop_fitness = pop_fitness

    def _selection(self):
        n_individuals = self._pop_sz[0]
        tournament = self._rd.choice(np.arange(n_individuals), self._k)
        tournament = np.sort(tournament)
        return tournament[0] # already sorted. return index to population

def main():
    aparse = argparse.ArgumentParser()
    aparse.add
    df = load("dataset.csv")
    X = df.iloc[:, 2:-2]
    y = df.iloc[:, -1]

    rf = RandomForestClassifier(n_estimators=300)
    fs = FS(rf, X, y, 10, 0.8, 0.2, 3, 0.6, 0)
    fs.generate_initial_population()
    for i in range(40):
        fs.next_generation()


if __name__ == "__main__":
    main()
